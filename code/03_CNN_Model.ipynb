{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: CNN Model\n",
    "\n",
    "The objective of this project is to create an image classification model by classifying x-rays whether someone has pneumonia or not. The tutorial I followed to run a convolutional neural network to identify whether one has pneumonia or not can be found from [tensorflow.com](https://www.tensorflow.org/tutorials/images/classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# For reproducible results:\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "<b>data</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>PNEUMONIA</b>: [pneumonia_0.jpg, pneumonia_1.jpg, pneumonia_2.jpg ....]\n",
    "    |______ <b>NORMAL</b>: [normal_0.jpg, normal_1.jpg, normal_2.jpg ...]\n",
    "|__ <b>test</b>\n",
    "    |______ <b>PNEUMONIA</b>: [pneumonia_0.jpg, pneumonia_1.jpg, pneumonia_2.jpg ....]\n",
    "    |______ <b>NORMAL</b>: [normal_0.jpg, normal_1.jpg, normal_2.jpg ...]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training normal images: 1341\n",
      "Total training pneumonia images: 3875\n",
      "Total test normal images: 242\n",
      "Total train normal images: 398\n",
      "--\n",
      "Total training images: 5216\n",
      "Total test images: 640\n"
     ]
    }
   ],
   "source": [
    "train_directory = '../data/train/'\n",
    "test_directory = '../data/test/'\n",
    "\n",
    "normal_tr = glob.glob('../data/train/NORMAL/*.jpeg')\n",
    "pneumonia_tr = glob.glob('../data/train/PNEUMONIA/*.jpeg')\n",
    "\n",
    "normal_test = glob.glob('../data/test/NORMAL/*.jpeg')\n",
    "pneumonia_test = glob.glob('../data/test/PNEUMONIA/*.jpeg')\n",
    "\n",
    "\n",
    "print(f\"Total training normal images: {len(normal_tr)}\")\n",
    "print(f\"Total training pneumonia images: {len(pneumonia_tr)}\")\n",
    "print(f\"Total test normal images: {len(normal_test)}\")\n",
    "print(f\"Total train normal images: {len(pneumonia_test)}\")\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", len(glob.glob('../data/train/*/*.jpeg')))\n",
    "print(\"Total test images:\", len(glob.glob('../data/test/*/*.jpeg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading `train_data` and `test_data` which are the images transformed into floating point tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 640 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "%run '../assets/tensor_data.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data and test_data have successfully been imported.\n"
     ]
    }
   ],
   "source": [
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# list of objects\n",
    "variables = [x for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "\n",
    "if 'train_data' in variables and 'test_data' in variables:\n",
    "    print('train_data and test_data have successfully been imported.')\n",
    "else:\n",
    "    print('train_data and test_data have not been imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "The images now must be processed. As mentioned before in Notebook 1, each images' resolution, pixel width and height, zoom, and angle is different, so the images have to be normalized by using keras' `ImageDataGenerator`.\n",
    "\n",
    "`ImageDataGenerator` will transform images to floating point tensors, which can the be inputted into the neural network. The following steps will be performed:\n",
    "1. Images will be read in\n",
    "2. Images will be resized to [224x224 pixels](https://datascience.stackexchange.com/questions/16601/reason-for-square-images-in-deep-learning) because many models such as VGG and ResNet like squares apparently.<font color = 'red'>***</font>\n",
    "    \n",
    "3. Images will then be converted to floating point tensors\n",
    "4. Tensors will be rescaled from values between 0 and 255 to values between 0 and 1 because small input values are better to train for neural networks.\n",
    "\n",
    "The data augmentation portion is necessary to create more inputs/observations to train the model. More training data will be generated by reshaping and modifying existing training images. The following will be applied for augmentation:\n",
    "\n",
    "1. `horizontal_flip = True` - enough said\n",
    "2. `rotation_range = 30` - randomly rotate an image by 30 degrees\n",
    "3. `zoom_range=0.3` - randomly zoom into an image up to 30%\n",
    "\n",
    "\n",
    "<font color = 'red'>***</font> More in depth explanation: Increasing input image size will lead to an increase in noise and variance that will require the network to deal with more processing, such asmore pooling or layers.\n",
    "    \n",
    "Documentation source for pre-processing - [keras - preprocessing](https://keras.io/preprocessing/image/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
